{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool runner\n",
    "\n",
    "Use this notebook to operate the `toolbox_runner` backend from a Python environment. You need to have docker installed and built all images found in `./images`.\n",
    "Only images that are tagged with a tag prefixed *tbr_* will be recognized as tool. Then, you can run the tool and obtain the result from within Python, without\n",
    "the need to install all dependencies or the environment of the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all tools found and inspect them\n",
    "\n",
    "Each tool exposes a config file to learn about its parameters (and one day also the outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_runner.run import list_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'variogram': variogram: Variogram fitting  FROM tbr_gs:latest VERSION: 1.1,\n",
       " 'kriging': kriging: Kriging interpolation  FROM tbr_gs:latest VERSION: 1.0,\n",
       " 'simulation': simulation: Geostatistical simulation  FROM tbr_gs:latest VERSION: 1.0,\n",
       " 'foobar': foobar: Foo Bar  FROM tbr_octave:latest VERSION: 0.1,\n",
       " 'profile': profile: Dataset Profile  FROM tbr_profile:latest VERSION: 0.1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = list_tools(as_dict=True)\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pick a tool and learn about the parameter names and their types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variogram fitting\n",
      "-------------\n",
      "Estimate an empirical variogram and fit a model\n",
      "\n",
      "Parameters\n",
      "-------------\n",
      "coordinates:\t\tfile\n",
      "values:\t\tfile\n",
      "n_lags:\t\tinteger\n",
      "model:\t\tenum\n",
      "estimator:\t\tenum\n",
      "maxlag:\t\tstring\n",
      "fit_method:\t\tenum\n"
     ]
    }
   ],
   "source": [
    "vario = tools.get('variogram')\n",
    "\n",
    "print(vario.title)\n",
    "print('-------------')\n",
    "print(vario.description)\n",
    "print('\\nParameters\\n-------------')\n",
    "for key, conf in vario.parameters.items():\n",
    "    print(f\"{key}:\\t\\t{conf['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can grab your data from anywhere. The coordinates and values needs to be a N-D and 1-D array of same length. You can supply the path to a `.mat` file, or use the numpy ecosystem to pass two arrays. You can find an example in the source for the geostatistical tools image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../images/skgstat/in/meuse.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb Zelle 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# use pandas to read the file\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../images/skgstat/in/meuse.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# extract the numpy arrays\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mirko/Dropbox/python/tool-runner/frontends/run_tool.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m coords \u001b[39m=\u001b[39m df[[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../images/skgstat/in/meuse.csv'"
     ]
    }
   ],
   "source": [
    "# use pandas to read the file\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../images/skgstat/in/meuse.csv')\n",
    "\n",
    "# extract the numpy arrays\n",
    "coords = df[['x', 'y']].values\n",
    "vals = df.lead.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `Tool.run` function to call the tool inside the docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results cached at ./1666766315_variogram.tar.gz\n"
     ]
    }
   ],
   "source": [
    "step_path = vario.run(result_path='./', coordinates=coords, values=vals, model='exponential', n_lags=15, maxlag='median')\n",
    "print(f'Results cached at {step_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = tools.get('profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "./1666795347_profile.tar.gz"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = profile.run(result_path='./', data=df)\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./out/STDERR.log', './out/STDOUT.log', './out/report.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.10/site-packages/multimethod/__init__.py:315: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  return func(*args, **kwargs)\n",
      "\n",
      "Summarize dataset:   0%|          | 0/8 [00:00<?, ?it/s, Describe variable:x]\n",
      "Summarize dataset:  12%|█▎        | 1/8 [00:00<00:00, 77.45it/s, Describe variable:y]\n",
      "Summarize dataset:  25%|██▌       | 2/8 [00:00<00:00, 141.17it/s, Describe variable:lead]\n",
      "Summarize dataset:  38%|███▊      | 3/8 [00:00<00:00, 204.74it/s, Get variable types]    \n",
      "Summarize dataset:  27%|██▋       | 4/15 [00:00<00:00, 270.92it/s, Calculate auto correlation]\n",
      "Summarize dataset:  33%|███▎      | 5/15 [00:00<00:00, 280.26it/s, Calculate spearman correlation]\n",
      "Summarize dataset:  40%|████      | 6/15 [00:00<00:00, 331.01it/s, Calculate pearson correlation] \n",
      "Summarize dataset:  47%|████▋     | 7/15 [00:00<00:00, 383.64it/s, Calculate kendall correlation]\n",
      "Summarize dataset:  53%|█████▎    | 8/15 [00:00<00:00, 420.30it/s, Calculate cramers correlation]\n",
      "Summarize dataset:  60%|██████    | 9/15 [00:00<00:00, 471.25it/s, Calculate phi_k correlation]  \n",
      "Summarize dataset:  67%|██████▋   | 10/15 [00:00<00:00, 15.55it/s, Calculate phi_k correlation]\n",
      "Summarize dataset:  67%|██████▋   | 10/15 [00:00<00:00, 15.55it/s, Get scatter matrix]         \n",
      "Summarize dataset:  42%|████▏     | 10/24 [00:00<00:00, 15.55it/s, scatter x, x]      \n",
      "Summarize dataset:  46%|████▌     | 11/24 [00:00<00:00, 15.55it/s, scatter y, x]\n",
      "Summarize dataset:  50%|█████     | 12/24 [00:00<00:00, 15.55it/s, scatter lead, x]\n",
      "Summarize dataset:  54%|█████▍    | 13/24 [00:00<00:00, 16.61it/s, scatter lead, x]\n",
      "Summarize dataset:  54%|█████▍    | 13/24 [00:00<00:00, 16.61it/s, scatter x, y]   \n",
      "Summarize dataset:  58%|█████▊    | 14/24 [00:00<00:00, 16.61it/s, scatter y, y]\n",
      "Summarize dataset:  62%|██████▎   | 15/24 [00:00<00:00, 16.61it/s, scatter lead, y]\n",
      "Summarize dataset:  67%|██████▋   | 16/24 [00:00<00:00, 19.02it/s, scatter lead, y]\n",
      "Summarize dataset:  67%|██████▋   | 16/24 [00:00<00:00, 19.02it/s, scatter x, lead]\n",
      "Summarize dataset:  71%|███████   | 17/24 [00:00<00:00, 19.02it/s, scatter y, lead]\n",
      "Summarize dataset:  75%|███████▌  | 18/24 [00:00<00:00, 19.02it/s, scatter lead, lead]\n",
      "Summarize dataset:  79%|███████▉  | 19/24 [00:00<00:00, 19.02it/s, Get dataframe statistics]\n",
      "Summarize dataset:  77%|███████▋  | 20/26 [00:00<00:00, 19.02it/s, Missing diagram bar]     \n",
      "Summarize dataset:  81%|████████  | 21/26 [00:01<00:00, 23.08it/s, Missing diagram bar]\n",
      "Summarize dataset:  81%|████████  | 21/26 [00:01<00:00, 23.08it/s, Missing diagram matrix]\n",
      "Summarize dataset:  85%|████████▍ | 22/26 [00:01<00:00, 23.08it/s, Take sample]           \n",
      "Summarize dataset:  88%|████████▊ | 23/26 [00:01<00:00, 23.08it/s, Detecting duplicates]\n",
      "Summarize dataset:  92%|█████████▏| 24/26 [00:01<00:00, 23.08it/s, Get alerts]          \n",
      "Summarize dataset:  96%|█████████▌| 25/26 [00:01<00:00, 23.08it/s, Get reproduction details]\n",
      "Summarize dataset: 100%|██████████| 26/26 [00:01<00:00, 23.08it/s, Completed]               \n",
      "Summarize dataset: 100%|██████████| 26/26 [00:01<00:00, 24.18it/s, Completed]\n",
      "\n",
      "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "\n",
      "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00,  7.88it/s]\n",
      "\n",
      "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/src/run.py\", line 22, in <module>\n",
      "    profile.to_json('/out/report.json')\n",
      "TypeError: ProfileReport.to_json() takes 1 positional argument but 2 were given\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(step.get_file('./out/STDERR.log').decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is weird, but is works\n",
    "from IPython.display import display, HTML\n",
    "html = step.get_file('./out/report.html').decode()\n",
    "\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c57ebfed52ffd848a0d2f36f1ea9c0a9060c9b67397fbb725d6aa92a9494b08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
